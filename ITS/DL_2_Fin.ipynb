{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89695a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "# Load the IMDB dataset\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8212d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the data\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the DNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(10000,)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37dfd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=4,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a47f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"\\nTest Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.datasets import imdb\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the IMDB dataset\n",
    "# max_features = 10000  # consider only the top 10,000 most common words\n",
    "# maxlen = 100  # truncate reviews after 100 words\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "# # Retrieve the word index from the IMDB dataset\n",
    "# word_index = imdb.get_word_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Preprocess the data\n",
    "# x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "# x_test = pad_sequences(x_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the model\n",
    "# model = Sequential([\n",
    "#     Embedding(max_features, 8, input_length=maxlen),\n",
    "#     Flatten(),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Train the model\n",
    "# model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Evaluate the model\n",
    "# test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "# print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9738d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example prediction\n",
    "# def predict_review_sentiment(review):\n",
    "#     # Tokenize and pad the input review\n",
    "#     review_seq = pad_sequences([[word_index[word] if word_index[word] < max_features else 0 for word in review.split()]], maxlen=maxlen)\n",
    "#     # Predict sentiment (0: negative, 1: positive)\n",
    "#     prediction = model.predict(review_seq)\n",
    "#     if prediction >= 0.5:\n",
    "#         return \"Positive\"\n",
    "#     else:\n",
    "#         return \"Negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example usage\n",
    "# positive_review = \"This movie was fantastic! I loved every moment of it.\"\n",
    "# negative_review = \"What a waste of time. Terrible acting and a nonsensical plot.\"\n",
    "\n",
    "# print(\"Predicted sentiment for positive review:\", predict_review_sentiment(positive_review))\n",
    "# print(\"Predicted sentiment for negative review:\", predict_review_sentiment(negative_review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e41acb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
